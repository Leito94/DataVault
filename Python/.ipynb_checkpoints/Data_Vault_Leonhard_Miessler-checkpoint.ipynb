{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataVault:\n",
    "    def __init__(self, db):\n",
    "        self.db_name = db\n",
    "        self.RS = 1 # changes later\n",
    "        \n",
    "        # list of our hubs\n",
    "        self.hub_list = [\"Player\", \"League\", \"Team\"]       \n",
    "        self.sat_dict = {\"HSAT\" : [\"HSAT_Team\", \"HSAT_Team_Attributes\", \"HSAT_League\",\"HSAT_Player\",\"HSAT_Player_Attributes\"],\n",
    "                         \"LSAT\" : [\"LSAT_Match_Attributes\", \"LSAT_Match_Bookmakers\"],\n",
    "                         \"BSAT\" : ['BSAT_Goal', 'BSAT_Shoton', 'BSAT_Shotoff', 'BSAT_Foulcommit', 'BSAT_Card', \n",
    "                                   'BSAT_Cross', 'BSAT_Corner', 'BSAT_Possession']}\n",
    "        \n",
    "    def connect_to_db(self):\n",
    "        self.conn = sqlite3.connect(self.db_name)\n",
    "        self.cursor = self.conn.cursor()\n",
    "    \n",
    "    def disconnect(self):\n",
    "        self.conn.close()\n",
    "        \n",
    "    def get_table_names(self) -> list:\n",
    "        \"\"\"returns a list of all the names of the tables of a SQL database\"\"\"\n",
    "        query = (\n",
    "        'SELECT name FROM sqlite_master '\n",
    "        'WHERE type IN (\"table\", \"view\") '\n",
    "        'AND name NOT LIKE \"sqlite_%\"'\n",
    "        ';'\n",
    "        )\n",
    "        table = pd.read_sql(query, con=self.conn)\n",
    "        self.all_tables = table['name'].to_list()\n",
    "        \n",
    "        self.hub_tables, self.table_names = [], []\n",
    "        for table in self.all_tables:\n",
    "            \n",
    "            if table[:4] == \"HUB_\":# or table in self.links:\n",
    "                self.hub_tables.append(table)\n",
    "            else:\n",
    "                self.table_names.append(table)\n",
    "        return self.hub_tables, self.table_names\n",
    "                \n",
    "\n",
    "    def get_column_names(self, tables) -> list:\n",
    "        \"\"\"returns a list of the column names of a table from a SQL database\n",
    "        if index was created properly\"\"\"\n",
    "        \n",
    "        self.columns = {}\n",
    "        for table in tables:\n",
    "            df_column = pd.read_sql(f'PRAGMA table_info({table});', con=self.conn)\n",
    "            self.columns[table] = df_column['name'].to_list()\n",
    "            \n",
    "        return self.columns\n",
    "    \n",
    "    def get_hub_primary_key(self, table) -> str:\n",
    "        \"\"\"returns the name of the primary keys of a table from a SQL database\"\"\"\n",
    "        \n",
    "        hub_pk = pd.read_sql(f\"pragma table_info({table});\", con = self.conn)[\"name\"].values[1]\n",
    "        return hub_pk\n",
    "    \n",
    "    def get_sat_primary_key(self, table) -> str:\n",
    "        \"\"\"returns the name of the primary keys of a table from a SQL database\"\"\"\n",
    "        \n",
    "        hub_pk = pd.read_sql(f\"pragma table_info({table});\", con = self.conn)[\"name\"].values[2]\n",
    "        return hub_pk\n",
    "    \n",
    "    def get_primary_keys(self) -> str:\n",
    "        \"\"\"returns the name of the primary keys of a table from a SQL database if index was created properly\"\"\"\n",
    "        \n",
    "        # get all columns\n",
    "        cols = self.get_column_names(self.table_names)\n",
    "        # dict for the keys\n",
    "        self.p_keys = {}\n",
    "        for table in self.table_names:\n",
    "            try:\n",
    "                info = pd.read_sql(f\"PRAGMA table_info({table})\", con = self.conn);\n",
    "                ind = info.index[info.pk == 1].item()\n",
    "                self.p_keys[table] = cols[table][ind]\n",
    "            except:\n",
    "                print(f\"Table 'index_info' not found, can't get primary key of {table}\")\n",
    "        return self.p_keys\n",
    "        \n",
    "    def hash_row(self, column_values):\n",
    "        \"\"\"function to create a hashkey of a row of a a list of values\"\"\"\n",
    "        string_vars = [str(c).strip().upper() if c is not None else \"\" for c in column_values]\n",
    "        string_vars = [c.replace(\" \", \"_\") for c in string_vars]\n",
    "        # join them\n",
    "        one_string = \"_\".join(string_vars)\n",
    "\n",
    "        # hash gen\n",
    "        hash_gene = hashlib.new(\"MD5\")\n",
    "\n",
    "        hash_gene.update(one_string.encode(\"utf-8\")) \n",
    "\n",
    "        return hash_gene.hexdigest()\n",
    "    \n",
    "    def get_foreign_keyss(self):\n",
    "        \"\"\"returns the name(s) of the foreign key of a table from a SQL database if index was created properly\"\"\"\n",
    "        \n",
    "        self.f_keys = {}\n",
    "        \n",
    "        p_key_col_dict = {k:v for k, v in zip(self.p_keys.values(), self.columns.values())}\n",
    "        \n",
    "        for p_key, col_names, table in zip(p_key_col_dict.keys(), p_key_col_dict.values(), self.table_names):\n",
    "            f_list = []\n",
    "            for col_name in col_names:\n",
    "                if col_name in p_key_col_dict.keys() and col_name!= p_key:\n",
    "                    f_list.append(col_name)\n",
    "            self.f_keys[table] = f_list\n",
    "        return self.f_keys\n",
    "    \n",
    "    def create_hubs(self):\n",
    "        \"\"\"function to create a hub dataframe\"\"\"\n",
    "        \n",
    "        print(\"creating hubs...\")\n",
    "        \n",
    "        # necesary functions\n",
    "        self.connect_to_db()\n",
    "        self.get_table_names()\n",
    "        self.get_primary_keys()\n",
    "        \n",
    "        self.created_hubs = []\n",
    "        for table in self.hub_list:\n",
    "            try:\n",
    "                # create hub table name\n",
    "                hub_table = \"HUB_\" + table\n",
    "                \n",
    "                # append to list\n",
    "                self.created_hubs.append(hub_table)\n",
    "                print(\"Creating \" + hub_table)\n",
    "                \n",
    "                # drop if exists\n",
    "                self.cursor.execute(f\"\"\"DROP TABLE IF EXISTS {hub_table};\"\"\")\n",
    "                # create table\n",
    "                self.cursor.execute(f\"\"\"CREATE TABLE IF NOT EXISTS {hub_table}(\n",
    "                HK VARYINGN CHARACTER(64) NOT NULL PRIMARY KEY,\n",
    "                BK INTEGER NOT NULL,\n",
    "                RS INTEGER NOT NULL,\n",
    "                LDTS DATETIME NOT NULL\n",
    "                \n",
    "                );\"\"\")\n",
    "                \n",
    "                print(f\"Successfully created {hub_table}\")\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                print(f\"Could not create hub table {table}\")\n",
    "        \n",
    "    def fill_hubs(self):\n",
    "        \n",
    "        print(\"filling hubs...\")\n",
    "        \n",
    "        # necesary functions\n",
    "        self.connect_to_db()\n",
    "        self.get_table_names()\n",
    "        self.get_primary_keys()\n",
    "        \n",
    "        for table, hub_table in zip(self.hub_list, self.created_hubs):\n",
    "            try:\n",
    "                \n",
    "                print(\"filling \" + hub_table)\n",
    "                \n",
    "                # get the primary key of that table\n",
    "                p_key = self.get_hub_primary_key(table)\n",
    "                print(\"pkey: \" + p_key)\n",
    "                self.cursor.execute(f\"\"\"INSERT INTO {hub_table}(HK, BK,LDTS,RS) select {p_key}, {p_key},\n",
    "                date(\"now\"), 1 from {table} ORDER BY {p_key} ASC;\"\"\")\n",
    "\n",
    "                HUB = pd.read_sql(f\"SELECT * FROM {hub_table}\", con = self.conn)\n",
    "                HUB[\"HK\"] = [self.hash_row(HUB.loc[i]) for i in range(len(HUB))]\n",
    "                \n",
    "                HUB.to_sql(f'{hub_table}', self.conn, if_exists='replace',  index=False,\n",
    "                       dtype={\"HK\": \"TEXT NOT NULL PRIMARY KEY\", \"BK\":\"INTEGER\", \"LDTS\": \"DATETIME\", \"RS\": \"INTEGER\"})\n",
    "                \n",
    "                print(\"Successfully filled \" + hub_table)\n",
    "            except:\n",
    "                \n",
    "                print(\"Could not fill \" + hub_table)\n",
    "             \n",
    "    def create_links(self):\n",
    "        \"\"\"Function to create and fill links\"\"\"\n",
    "        \n",
    "        # necesary functions\n",
    "        self.connect_to_db()\n",
    "        self.get_table_names()\n",
    "        self.get_primary_keys()\n",
    "        \n",
    "        self.created_links = []\n",
    "            \n",
    "        # create name\n",
    "        link_table_1 = \"LINK_Match\"\n",
    "\n",
    "        print(\"creating \"+ link_table_1)\n",
    "        # drop if exists\n",
    "        self.cursor.execute(f\"\"\"DROP TABLE IF EXISTS {link_table_1};\"\"\")\n",
    "\n",
    "        self.cursor.execute(f\"\"\"CREATE TABLE {link_table_1}(\n",
    "            HK VARYINGN CHARACTER(64) NOT NULL PRIMARY KEY,\n",
    "            HK_away_team VARYINGN CHARACTER(64) NOT NULL, \n",
    "            HK_home_team VARYINGN CHARACTER(64) NOT NULL, \n",
    "            HK_league VARYINGN CHARACTER(64) NOT NULL, \n",
    "            LDTS DATETIME NOT NULL,\n",
    "            RS INTEGER NOT NULL,\n",
    "            FOREIGN KEY(HK_away_team) REFERENCES HUB_Team(HK),\n",
    "            FOREIGN KEY(HK_home_team) REFERENCES HUB_Team(HK),\n",
    "            FOREIGN KEY(HK_league) REFERENCES HUB_league(HK)\n",
    "            );\"\"\")\n",
    "        print(\"created \" + link_table_1)\n",
    "        \n",
    "        self.created_links.append(link_table_1)\n",
    "        \n",
    "        link_table_2 = \"LINK_Match_Player\"\n",
    "\n",
    "        print(\"creating \"+ link_table_2)\n",
    "        # drop if exists\n",
    "        self.cursor.execute(f\"\"\"DROP TABLE IF EXISTS {link_table_2};\"\"\")\n",
    "\n",
    "        self.cursor.execute(f\"\"\"CREATE TABLE {link_table_2}(\n",
    "            HK VARYINGN CHARACTER(64) NOT NULL PRIMARY KEY,\n",
    "            HK_Link_Match VARYINGN CHARACTER(64) NOT NULL,\n",
    "            HK_Player VARYINGN CHARACTER(64) NOT NULL,\n",
    "            LDTS DATETIME NOT NULL,\n",
    "            RS INTEGER NOT NULL,\n",
    "            FOREIGN KEY(HK_Link_Match) REFERENCES LINK_Match(HK),\n",
    "            FOREIGN KEY(HK_Player) REFERENCES HUB_Player(HK)\n",
    "            );\"\"\")\n",
    "        print(\"created \" + link_table_2)\n",
    "        self.created_links.append(link_table_2)\n",
    "        \n",
    "    def fill_links(self):\n",
    "        \n",
    "        \n",
    "        print(\"filling links...\")\n",
    "        \n",
    "        # necesary functions\n",
    "        self.connect_to_db()\n",
    "        self.get_table_names()\n",
    "        self.get_primary_keys()\n",
    "        #---------------------------------------------------------------------------------------------#\n",
    "        # LINK 1\n",
    "        # create name\n",
    "        link_table_1 = \"LINK_Match\"\n",
    "        print(\"filling \" + link_table_1)\n",
    "        # match_df\n",
    "        match_df = pd.read_sql(\"select * from Match\", con = self.conn)\n",
    "        \n",
    "        # get the hash keys\n",
    "        teams_HK = pd.read_sql(\"select HK, BK from HUB_Team\", con = self.conn)\n",
    "        league_HK = pd.read_sql(\"select HK, BK from HUB_League\", con = self.conn)\n",
    "        \n",
    "        hk_home_list, hk_away_list, hk_league_list = [], [], []\n",
    "        for i in range(len(match_df)):\n",
    "            # ids\n",
    "            home_id = match_df.iloc[i][\"home_team_api_id\"]\n",
    "            away_id = match_df.iloc[i][\"away_team_api_id\"]\n",
    "            league_id = match_df.iloc[i][\"league_id\"]\n",
    "            \n",
    "            #hashkeys\n",
    "            hk_home = teams_HK[teams_HK.BK == home_id][\"HK\"].item()\n",
    "            hk_away = teams_HK[teams_HK.BK == away_id][\"HK\"].item()\n",
    "            hk_league = league_HK[league_HK.BK == league_id][\"HK\"].item()\n",
    "            \n",
    "            # append to list\n",
    "            hk_home_list.append(hk_home)\n",
    "            hk_away_list.append(hk_away)\n",
    "            hk_league_list.append(hk_league)\n",
    "            \n",
    "        link_hks = []\n",
    "        # create the link_hash\n",
    "        for home_hk, away_hk, league_hk, date in zip(hk_home_list, hk_away_list, hk_league_list, match_df.date.tolist()):\n",
    "            var_list = [home_hk, away_hk, league_hk, date, self.RS]\n",
    "            \n",
    "            # calculate hash\n",
    "            link_hk = self.hash_row(var_list)\n",
    "            link_hks.append(link_hk)\n",
    "        \n",
    "        # insert into the link table\n",
    "        match_link_df = pd.DataFrame({\n",
    "            \"HK\" : link_hks,\n",
    "            \"HK_away_team\" : hk_away_list,\n",
    "            \"HK_home_team\" : hk_home_list,\n",
    "            \"HK_league\" : hk_league_list,\n",
    "            \"LDTS\" : match_df.date,\n",
    "            \"RS\" : self.RS\n",
    "        })\n",
    "        \n",
    "        match_link_df.to_sql(name = link_table_1,con=self.conn, if_exists='append', index = False,\n",
    "                              dtype={\"HK\": \"VARYINGN CHARACTER(64) NOT NULL PRIMARY KEY\",\n",
    "                                     \"HK_away_team\" : \"VARYINGN CHARACTER(64) NOT NULL\",\n",
    "                                     \"HK_home_team\" : \"VARYINGN CHARACTER(64) NOT NULL\",\n",
    "                                     \"HK_league\" : \"VARYINGN CHARACTER(64) NOT NULL\",\n",
    "                                     \"LDTS\": \"DATETIME NOT NULL\",\n",
    "                                     \"RS\": \"INT NOT NULL\"\n",
    "                                     })\n",
    "        print(\"succsessfully filled \" + link_table_1)\n",
    "        # LINK 2 --------------------------------------------------------------------------------------------#\n",
    "        # create name\n",
    "        link_table_2 = \"LINK_Match_Player\"\n",
    "        print(\"filling \" + link_table_2)\n",
    "            \n",
    "        hub_player = pd.read_sql(\"select * from HUB_Player\", con = self.conn)\n",
    "        link_match = pd.read_sql(\"select * from LINK_Match\", con = self.conn)\n",
    "        match_df = pd.read_sql(\"select * from Match\", con = self.conn)\n",
    "\n",
    "        player_columns = []\n",
    "        for i in range(1, 12):\n",
    "            player_columns.append(\"home_player_\" + str(i))\n",
    "            player_columns.append(\"away_player_\" + str(i))\n",
    "\n",
    "        player_columns.append(\"match_api_id\")\n",
    "\n",
    "        match_df = match_df[player_columns]\n",
    "\n",
    "        melted_player_df = match_df.melt(id_vars = \"match_api_id\", var_name = \"player\", value_name=\"player_api_id\")\n",
    "        #melted_player_df = melted_player_df.drop_duplicates()\n",
    "        \n",
    "        player_hash_keys, match_hash_keys = [], [] \n",
    "        for index, match_id in enumerate(melted_player_df.match_api_id.unique()):\n",
    "            # create a dataframe with that match\n",
    "            match_df = melted_player_df[melted_player_df.match_api_id == match_id]\n",
    "            #print(len(match_df))\n",
    "\n",
    "            # get the match hash key from the link_match table\n",
    "            match_hk = link_match.iloc[index][\"HK\"]\n",
    "            for player_id in match_df.player_api_id:\n",
    "                try:\n",
    "                    player_hk = hub_player[hub_player.BK == player_id][\"HK\"].item()\n",
    "                    player_hash_keys.append(player_hk)\n",
    "                    match_hash_keys.append(match_hk)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        # create the link_match_player_HK\n",
    "        link_match_hash_keys = []\n",
    "        for player_hk, match_hk in zip(player_hash_keys, match_hash_keys):\n",
    "            match_link_HK = self.hash_row([player_hk, match_hk, self.RS])\n",
    "            link_match_hash_keys.append(match_link_HK)\n",
    "            \n",
    "        LDTS = datetime.datetime.now()\n",
    "        \n",
    "        LINK_match_player_df = pd.DataFrame({\n",
    "            \"HK\" : link_match_hash_keys,\n",
    "            \"HK_Link_Match\" : match_hash_keys,\n",
    "            \"HK_Player\" : player_hash_keys,\n",
    "            \"LDTS\" : LDTS,\n",
    "            \"RS\" : self.RS\n",
    "        })\n",
    "        \n",
    "        LINK_match_player_df = LINK_match_player_df.drop_duplicates()\n",
    "        \n",
    "        # into the database\n",
    "        LINK_match_player_df.to_sql(name = link_table_2,con=self.conn, if_exists='append', index = False,\n",
    "                              dtype={\"HK\": \"VARYINGN CHARACTER(64) NOT NULL PRIMARY KEY\",\n",
    "                                     \"HK_Link_Match\" : \"VARYINGN CHARACTER(64) NOT NULL\",\n",
    "                                     \"HK_Player\" : \"VARYINGN CHARACTER(64) NOT NULL\",\n",
    "                                     \"LDTS\": \"DATETIME NOT NULL\",\n",
    "                                     \"RS\": \"INT NOT NULL\"\n",
    "                                     })\n",
    "        \n",
    "        print(\"succsessfully filled \" + link_table_2)\n",
    "                         \n",
    "                         \n",
    "    def create_and_fill_hub_sats(self):\n",
    "            \n",
    "        # necesary functions\n",
    "        self.connect_to_db()\n",
    "        self.get_table_names()\n",
    "        self.get_primary_keys()\n",
    "                         \n",
    "        # HUB_Satelites-----------------------------------------------------------------------------------------------#\n",
    "        hub_sat_list = self.sat_dict[\"HSAT\"]\n",
    "        \n",
    "        # loop over sat_list\n",
    "        for sat in hub_sat_list:\n",
    "            print(\"creating \" + sat)\n",
    "            # get the corresponding name of the sat\n",
    "            sat_df_split = sat.split(\"_\")\n",
    "            sat_df_name = \"_\".join(sat_df_split[1:])\n",
    "            hub_name = sat_df_split[1]\n",
    "            print(sat_df_name)\n",
    "            \n",
    "            # read original table and hub_table\n",
    "            sat_df = pd.read_sql(f\"SELECT * from {sat_df_name}\", con = self.conn) \n",
    "\n",
    "            # get the colums from the original table that I need for the satelite\n",
    "            info = pd.read_sql(f\"PRAGMA table_info({sat_df_name})\", con = self.conn)\n",
    "            col_names = info[\"name\"]\n",
    "            col_type = info[\"type\"]\n",
    "            rel_cols = {}\n",
    "            for col_name, col_type in zip(col_names, col_type):\n",
    "                if \"id\" not in col_name:\n",
    "                    rel_cols[col_name] = \" \" + col_type + \",\" # add comma\n",
    "            # dict to string so I can add it to my create table\n",
    "            var_string = \"\"\n",
    "            for c, t in rel_cols.items():\n",
    "                var_string += c + t\n",
    "                \n",
    "            # create sat_table\n",
    "            # drop if exists\n",
    "            self.cursor.execute(f\"\"\"DROP TABLE IF EXISTS HSAT_{sat_df_name};\"\"\")\n",
    "            \n",
    "            # create the LDTS now\n",
    "            LDTS = datetime.datetime.now()\n",
    "            self.cursor.execute(f\"\"\"CREATE TABLE HSAT_{sat_df_name}(\n",
    "                HK VARYINGN CHARACTER(64) NOT NULL PRIMARY KEY,\n",
    "                HK_{hub_name} VARYINGN CHARACTER(64) NOT NULL,\n",
    "                LDTS DATETIME NOT NULL,\n",
    "                EDTS DATETIME NOT NULL,\n",
    "                RS INTEGER NOT NULL,\n",
    "                HD VARYINGN CHARACTER(64) NOT NULL,\n",
    "                {var_string}\n",
    "                FOREIGN KEY(HK_{hub_name}) REFERENCES HUB_{sat_df_name}(HK)\n",
    "                \n",
    "            );\"\"\")\n",
    "            \n",
    "            print(\"Successfully created \" + sat)\n",
    "            \n",
    "            # Filling HSATS--------------------------------------------------------------------#\n",
    "            \n",
    "            print(\"filling \" + sat)\n",
    "            \n",
    "            # the sat_df with the relevant cols\n",
    "            \n",
    "            # if \"attributes is in the table\"\n",
    "            if \"Attributes\" in sat_df_name:\n",
    "                # corresponding hub df\n",
    "                corr_hub_df = pd.read_sql(f\"select * from HUB_{hub_name}\", con = self.conn)\n",
    "                # attributes df\n",
    "                attr_df = pd.read_sql(f\"select * from {sat_df_name}\", con = self.conn)\n",
    "                p_k = self.get_sat_primary_key(sat_df_name)\n",
    "                \n",
    "                # relevant cols only\n",
    "                corr_hub_df = corr_hub_df[[\"HK\", \"BK\"]]\n",
    "                attr_df = attr_df[[p_k, \"date\"]]\n",
    "                sat_fk = attr_df.merge(corr_hub_df, how = \"inner\" , right_on= \"BK\",left_on=p_k)[\"HK\"].values\n",
    "                                                                                                    \n",
    "                sat_fk_df = attr_df.merge(corr_hub_df, how = \"inner\" , right_on= \"BK\",left_on=p_k)[[\"HK\", \"date\"]]\n",
    "            else:\n",
    "                # read in corresponding hub table\n",
    "                hub_df = pd.read_sql(f\"SELECT * from HUB_{hub_name}\", con = self.conn) \n",
    "                # hash key from hub\n",
    "                sat_fk = hub_df[\"HK\"].values\n",
    "                sat_fk_df = hub_df[\"HK\"]\n",
    "                \n",
    "            # make the sat table ready t be hashed\n",
    "            sat_attr_df = sat_df[rel_cols.keys()]\n",
    "            # hash the rows\n",
    "            sat_HD = [self.hash_row(sat_attr_df.iloc[i]) for i in range(len(sat_attr_df))]\n",
    "\n",
    "            # compute the Sat_HK\n",
    "            sat_HK = [self.hash_row([sat_fk_df.iloc[i], LDTS, self.RS]) for i in range(len(sat_fk_df))]\n",
    "            \n",
    "            EDTS = datetime.datetime.now()\n",
    "            \n",
    "            #return pd.DataFrame(sat_HK, sat_fk, LDTS, EDTS, \n",
    "            # create the sat df\n",
    "            print(len(sat_HK), len(sat_attr_df))\n",
    "            sat_attr_df[\"HK\"] = sat_HK\n",
    "            sat_attr_df[\"HK_\" + hub_name] = sat_fk\n",
    "            sat_attr_df[\"LDTS\"] = LDTS\n",
    "            sat_attr_df[\"EDTS\"] = EDTS\n",
    "            sat_attr_df[\"RS\"] = self.RS\n",
    "            sat_attr_df[\"HD\"] = sat_HD\n",
    "\n",
    "            # into the database\n",
    "            sat_attr_df.to_sql(name = sat,con=self.conn, if_exists='append', index = False)\n",
    "        \n",
    "            print(\"successfully filled \" + sat)\n",
    "            \n",
    "    def create_and_fill_link_sats(self):\n",
    "            \n",
    "        # necesary functions\n",
    "        self.connect_to_db()\n",
    "        self.get_table_names()\n",
    "        self.get_primary_keys()\n",
    "\n",
    "        # CREATING LSATS ----------------------------------------------------------#\n",
    "        link_table = \"Match\"\n",
    "        link_name = \"LINK_Match\"\n",
    "        link_sat_1 = \"LSAT_Match_Statistics\"\n",
    "        link_sat_2 = \"LSAT_Match_Bets\"\n",
    "        \n",
    "        info = pd.read_sql(f\"PRAGMA table_info ({link_table})\", con = self.conn)\n",
    "        col_names = info[\"name\"]\n",
    "        col_type = info[\"type\"]\n",
    "\n",
    "        match_attr_cols = col_names[:85]\n",
    "        match_attr_types = col_type[:85]\n",
    "\n",
    "        betting_cols = col_names[85:]\n",
    "        betting_types = col_type[:85]\n",
    "\n",
    "\n",
    "        rel_attr_cols = {}\n",
    "        for col_name, col_type in zip(match_attr_cols, match_attr_types):\n",
    "            if \"id\" not in col_name and len(col_name):\n",
    "                rel_attr_cols[col_name] = \" \" + col_type + \",\" # add comma\n",
    "        # dict to string so I can add it to my create table\n",
    "        var_string_attr = \"\"\n",
    "        for c, t in rel_attr_cols.items():\n",
    "            var_string_attr += c + t\n",
    "\n",
    "\n",
    "         # create link_table 1\n",
    "        # drop if exists\n",
    "        self.cursor.execute(f\"\"\"DROP TABLE IF EXISTS {link_sat_1};\"\"\")\n",
    "\n",
    "        # create the LDTS now\n",
    "        LDTS = datetime.datetime.now()\n",
    "        self.cursor.execute(f\"\"\"CREATE TABLE {link_sat_1}(\n",
    "            HK VARYINGN CHARACTER(64) NOT NULL PRIMARY KEY,\n",
    "            HK_{link_name} VARYINGN CHARACTER(64) NOT NULL,\n",
    "            LDTS DATETIME NOT NULL,\n",
    "            RS INTEGER NOT NULL,\n",
    "            HD VARYINGN CHARACTER(64) NOT NULL,\n",
    "            {var_string_attr}\n",
    "            FOREIGN KEY(HK_{link_name}) REFERENCES {link_name}(HK)\n",
    "\n",
    "        );\"\"\")\n",
    "            \n",
    "        \n",
    "        rel_bet_cols = {}\n",
    "        for col_name, col_type in zip(betting_cols, betting_types):\n",
    "            if \"id\" not in col_name and len(col_name):\n",
    "                rel_bet_cols[col_name] = \" \" + col_type + \",\" # add comma\n",
    "        # dict to string so I can add it to my create table\n",
    "        var_string_bets = \"\"\n",
    "        for c, t in rel_bet_cols.items():\n",
    "            var_string_bets += c + t\n",
    "                        \n",
    "        # drop if exists\n",
    "        self.cursor.execute(f\"\"\"DROP TABLE IF EXISTS {link_sat_2};\"\"\")\n",
    "        \n",
    "        # create the LDTS now\n",
    "        LDTS = datetime.datetime.now()\n",
    "        self.cursor.execute(f\"\"\"CREATE TABLE {link_sat_2}(\n",
    "            HK VARYINGN CHARACTER(64) NOT NULL PRIMARY KEY,\n",
    "            HK_{link_name} VARYINGN CHARACTER(64) NOT NULL,\n",
    "            LDTS DATETIME NOT NULL,\n",
    "            RS INTEGER NOT NULL,\n",
    "            HD VARYINGN CHARACTER(64) NOT NULL,\n",
    "            {var_string_bets}\n",
    "            FOREIGN KEY(HK_{link_name}) REFERENCES {link_name}(HK)\n",
    "\n",
    "        );\"\"\")\n",
    "        \n",
    "        # FILLING LSATS ------------------------------------------------------------------------------#\n",
    "        \n",
    "        # read in corresponding link table\n",
    "        match_df = pd.read_sql(f\"SELECT * from {link_table}\", con = self.conn) \n",
    "        link_df = pd.read_sql(f\"SELECT * from {link_name}\", con = self.conn) \n",
    "        LDTS = datetime.datetime.now()\n",
    "        \n",
    "        # FILL MATCH STATISTICS LSAT\n",
    "        rel_attr_df = match_df[rel_attr_cols.keys()]\n",
    "        \n",
    "        # hash key from hub\n",
    "        sat_fk = link_df[\"HK\"]\n",
    "                \n",
    "        # hash the rows\n",
    "        sat_HD = [self.hash_row(rel_attr_df.iloc[i]) for i in range(len(rel_attr_df))]\n",
    "\n",
    "        # compute the Sat_HK\n",
    "        sat_HK = [self.hash_row([sat_fk.iloc[i], LDTS, self.RS]) for i in range(len(sat_fk))]\n",
    "\n",
    "        # create the sat df\n",
    "        rel_attr_df[\"HK\"] = sat_HK\n",
    "        rel_attr_df[\"HK_\" + link_name] = sat_fk\n",
    "        rel_attr_df[\"LDTS\"] = LDTS\n",
    "        rel_attr_df[\"RS\"] = self.RS\n",
    "        rel_attr_df[\"HD\"] = sat_HD\n",
    "\n",
    "        # into the database\n",
    "        rel_attr_df.to_sql(name = link_sat_1,con=self.conn, if_exists='append', index = False)\n",
    "        \n",
    "        # FILL MATCH BET LSAT\n",
    "        rel_attr_df = match_df[rel_bet_cols.keys()]\n",
    "        \n",
    "        # hash key from hub\n",
    "        sat_fk = link_df[\"HK\"]\n",
    "                \n",
    "        # hash the rows\n",
    "        sat_HD = [self.hash_row(rel_attr_df.iloc[i]) for i in range(len(rel_attr_df))]\n",
    "\n",
    "        # compute the Sat_HK\n",
    "        sat_HK = [self.hash_row([sat_fk.iloc[i], LDTS, self.RS]) for i in range(len(sat_fk))]\n",
    "\n",
    "        # create the sat df\n",
    "        rel_attr_df[\"HK\"] = sat_HK\n",
    "        rel_attr_df[\"HK_\" + link_name] = sat_fk\n",
    "        rel_attr_df[\"LDTS\"] = LDTS\n",
    "        rel_attr_df[\"RS\"] = self.RS\n",
    "        rel_attr_df[\"HD\"] = sat_HD\n",
    "\n",
    "        # into the database\n",
    "        rel_attr_df.to_sql(name = link_sat_2,con=self.conn, if_exists='append', index = False)\n",
    "        \n",
    "    def create_and_fill_business_sats(self):\n",
    "        # necesary functions\n",
    "        self.connect_to_db()\n",
    "        self.get_table_names()\n",
    "        self.get_primary_keys()\n",
    "        \n",
    "        # IMPORT DATA ------------------------------------------------------------------#\n",
    "        # import the business satelites dfs\n",
    "        card_df = pd.read_csv(\"../Business_Satelite_Data/card_df.csv\", index_col = 0, low_memory=False)\n",
    "        corner_df = pd.read_csv(\"../Business_Satelite_Data/corner_df.csv\", index_col = 0, low_memory=False)\n",
    "        cross_df = pd.read_csv(\"../Business_Satelite_Data/cross_df.csv\", index_col = 0, low_memory=False)\n",
    "        foulcommit_df = pd.read_csv(\"../Business_Satelite_Data/foulcommit_df.csv\", index_col = 0, low_memory=False)\n",
    "        goal_df = pd.read_csv(\"../Business_Satelite_Data/goal_df.csv\", index_col = 0, low_memory=False)\n",
    "        possession_df = pd.read_csv(\"../Business_Satelite_Data/possession_df.csv\", index_col = 0, low_memory=False)\n",
    "        shotoff_df = pd.read_csv(\"../Business_Satelite_Data/shotoff_df.csv\", index_col = 0, low_memory=False)\n",
    "        shoton_df = pd.read_csv(\"../Business_Satelite_Data/shoton_df.csv\", index_col = 0, low_memory=False)\n",
    "\n",
    "        match_df = pd.read_sql(\"select * from Match\", con = self.conn)\n",
    "        link_match_df = pd.read_sql(\"select * from LINK_Match\", con = self.conn)\n",
    "\n",
    "        match_ids = match_df[\"match_api_id\"].values\n",
    "        match_hks = link_match_df[\"HK\"].values\n",
    "\n",
    "        match_id_hk = pd.DataFrame({\"match_api_id\" : match_ids, \n",
    "                           \"HK_Link_Match\" : match_hks})\n",
    "\n",
    "        # MERGING ------------------------------------------------------------------------------------#\n",
    "        \n",
    "        df_dict = {}\n",
    "        # loop over the business satelite data\n",
    "        business_sat_data = {\"card_df\" : card_df,\n",
    "                             \"cross_df\" : cross_df,\n",
    "                             \"corner_df\" : corner_df,\n",
    "                             \"foulcommit_df\" : foulcommit_df,\n",
    "                             \"goal_df\" : goal_df,\n",
    "                             \"possession_df\" : possession_df,\n",
    "                             \"shotoff_df\" : shotoff_df,\n",
    "                             \"shoton_df\" : shoton_df}\n",
    "\n",
    "        for name, df in business_sat_data.items():\n",
    "            merged_df = df.merge(match_id_hk, how = \"inner\" , right_on= \"match_api_id\",left_on=\"match_api_id\")\n",
    "            df_dict[name] = merged_df\n",
    "\n",
    "        #hash keys -----------------------------------------------------\n",
    "        for name, df in df_dict.items():\n",
    "            hk_df = df[[name.split(\"_\")[0] + \"_id\", \"HK_Link_Match\"]]\n",
    "            hk_df[\"RS\"] = 1\n",
    "            sat_hk = [self.hash_row(hk_df.iloc[i]) for i in range(len(hk_df))]\n",
    "            sat_attr_df = df.drop(columns = [\"HK_Link_Match\", name.split(\"_\")[0] + \"_id\"])\n",
    "            sat_HD = [self.hash_row(sat_attr_df.iloc[i]) for i in range(len(sat_attr_df))]\n",
    "            \n",
    "            # add new cols\n",
    "            df.insert(0, \"HK\", sat_hk)\n",
    "            df.insert(1, \"LDTS\", datetime.datetime.now())\n",
    "            df.insert(2, \"RS\", self.RS)\n",
    "            df.insert(3, \"HD\", sat_HD)\n",
    "            # to sql\n",
    "            df.to_sql(name = \"B_LSAT_\" + name.split(\"_\")[0] ,con=self.conn, if_exists='replace', index = False,\n",
    "                              dtype={\"HK\": \"VARYINGN CHARACTER(64) NOT NULL PRIMARY KEY\",\n",
    "                                     \"HK_Link_Match\" : \"VARYINGN CHARACTER(64) NOT NULL\",\n",
    "                                     \"LDTS\": \"DATETIME NOT NULL\",\n",
    "                                     \"HD\" : \"VARYINGN CHARACTER(64) NOT NULL\",\n",
    "                                     \"RS\": \"INT NOT NULL\"\n",
    "                                     })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating hubs...\n",
      "Creating HUB_Player\n",
      "Successfully created HUB_Player\n",
      "Creating HUB_League\n",
      "Successfully created HUB_League\n",
      "Creating HUB_Team\n",
      "Successfully created HUB_Team\n",
      "filling hubs...\n",
      "filling HUB_Player\n",
      "pkey: player_api_id\n",
      "Successfully filled HUB_Player\n",
      "filling HUB_League\n",
      "pkey: country_id\n",
      "Successfully filled HUB_League\n",
      "filling HUB_Team\n",
      "pkey: team_api_id\n",
      "Successfully filled HUB_Team\n",
      "creating LINK_Match\n",
      "created LINK_Match\n",
      "creating LINK_Match_Player\n",
      "created LINK_Match_Player\n",
      "filling links...\n",
      "filling LINK_Match\n",
      "succsessfully filled LINK_Match\n",
      "filling LINK_Match_Player\n",
      "succsessfully filled LINK_Match_Player\n",
      "creating HSAT_Team\n",
      "Team\n",
      "Successfully created HSAT_Team\n",
      "filling HSAT_Team\n",
      "299 299\n",
      "successfully filled HSAT_Team\n",
      "creating HSAT_Team_Attributes\n",
      "Team_Attributes\n",
      "Successfully created HSAT_Team_Attributes\n",
      "filling HSAT_Team_Attributes\n",
      "1458 1458\n",
      "successfully filled HSAT_Team_Attributes\n",
      "creating HSAT_League\n",
      "League\n",
      "Successfully created HSAT_League\n",
      "filling HSAT_League\n",
      "11 11\n",
      "successfully filled HSAT_League\n",
      "creating HSAT_Player\n",
      "Player\n",
      "Successfully created HSAT_Player\n",
      "filling HSAT_Player\n",
      "11060 11060\n",
      "successfully filled HSAT_Player\n",
      "creating HSAT_Player_Attributes\n",
      "Player_Attributes\n",
      "Successfully created HSAT_Player_Attributes\n",
      "filling HSAT_Player_Attributes\n",
      "183978 183978\n",
      "successfully filled HSAT_Player_Attributes\n"
     ]
    }
   ],
   "source": [
    "path = \"../../Databases/test_2.sqlite\"\n",
    "\n",
    "data_vault = DataVault(path)\n",
    "data_vault.create_hubs()\n",
    "data_vault.fill_hubs()\n",
    "data_vault.create_links()\n",
    "data_vault.fill_links()\n",
    "data_vault.create_and_fill_hub_sats()\n",
    "data_vault.create_and_fill_link_sats()\n",
    "data_vault.create_and_fill_business_sats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
